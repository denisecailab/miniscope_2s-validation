{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import itertools as itt\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import holoviews as hv\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from dask.distributed import Client, LocalCluster\n",
    "from holoviews.operation.datashader import datashade, regrid\n",
    "from holoviews.util import Dynamic\n",
    "from IPython.core.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set path and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up Initial Basic Parameters#\n",
    "minian_path = \".\"\n",
    "dpath = \"../data/m15/2022_08_04/12_34_43/miniscope_top/\"\n",
    "minian_ds_path = os.path.join(dpath, \"minian\")\n",
    "intpath = \"~/var/2s_validation/minian_intermediate\"\n",
    "intpath = os.path.normpath(os.path.expanduser(intpath))\n",
    "subset = dict(frame=slice(0, None))\n",
    "subset_mc = None\n",
    "interactive = True\n",
    "output_size = 100\n",
    "n_workers = int(os.getenv(\"MINIAN_NWORKERS\", 4))\n",
    "param_save_minian = {\n",
    "    \"dpath\": minian_ds_path,\n",
    "    \"overwrite\": True,\n",
    "}\n",
    "\n",
    "# Pre-processing Parameters#\n",
    "param_load_videos = {\n",
    "    \"pattern\": \"[0-9]+\\.avi$\",\n",
    "    \"dtype\": np.uint8,\n",
    "    \"downsample\": dict(frame=1, height=1, width=1),\n",
    "    \"downsample_strategy\": \"subset\",\n",
    "}\n",
    "param_denoise = {\"method\": \"median\", \"ksize\": 5}\n",
    "param_background_removal = {\"method\": \"tophat\", \"wnd\": 10}\n",
    "\n",
    "# Motion Correction Parameters#\n",
    "subset_mc = None\n",
    "param_estimate_motion = {\"dim\": \"frame\", 'alt_error': None, 'upsample': 10}\n",
    "\n",
    "# Initialization Parameters#\n",
    "param_seeds_init = {\n",
    "    \"wnd_size\": 10000,\n",
    "    \"method\": \"rolling\",\n",
    "    \"max_wnd\": 15,\n",
    "    \"diff_thres\": 5,\n",
    "    'stp_size': 5000\n",
    "}\n",
    "param_pnr_refine = {\"noise_freq\": 0.06, \"thres\": 1}\n",
    "param_ks_refine = {\"sig\": 0.05}\n",
    "param_seeds_merge = {\"thres_dist\": 10, \"thres_corr\": 0.8, \"noise_freq\": 0.06}\n",
    "param_initialize = {\"thres_corr\": 0.8, \"wnd\": 10, \"noise_freq\": 0.06}\n",
    "param_init_merge = {\"thres_corr\": 0.8}\n",
    "\n",
    "# CNMF Parameters#\n",
    "param_get_noise = {\"noise_range\": (0.06, 0.5)}\n",
    "param_first_spatial = {\n",
    "    \"dl_wnd\": 10,\n",
    "    \"sparse_penal\": 0.01,\n",
    "    \"size_thres\": (25, None),\n",
    "}\n",
    "param_first_temporal = {\n",
    "    \"noise_freq\": 0.06,\n",
    "    \"sparse_penal\": 1,\n",
    "    \"p\": 1,\n",
    "    \"add_lag\": 20,\n",
    "    \"jac_thres\": 0.2,\n",
    "}\n",
    "param_first_merge = {\"thres_corr\": 0.8}\n",
    "param_second_spatial = {\n",
    "    \"dl_wnd\": 10,\n",
    "    \"sparse_penal\": 0.01,\n",
    "    \"size_thres\": (25, None),\n",
    "}\n",
    "param_second_temporal = {\n",
    "    \"noise_freq\": 0.06,\n",
    "    \"sparse_penal\": 1,\n",
    "    \"p\": 1,\n",
    "    \"add_lag\": 20,\n",
    "    \"jac_thres\": 0.4,\n",
    "}\n",
    "\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MINIAN_INTERMEDIATE\"] = intpath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import minian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "sys.path.append(minian_path)\n",
    "from minian.cnmf import (\n",
    "    compute_AtC,\n",
    "    compute_trace,\n",
    "    get_noise_fft,\n",
    "    smooth_sig,\n",
    "    unit_merge,\n",
    "    update_spatial,\n",
    "    update_temporal,\n",
    "    update_background,\n",
    ")\n",
    "from minian.initialization import (\n",
    "    gmm_refine,\n",
    "    initA,\n",
    "    initC,\n",
    "    intensity_refine,\n",
    "    ks_refine,\n",
    "    pnr_refine,\n",
    "    seeds_init,\n",
    "    seeds_merge,\n",
    ")\n",
    "from minian.motion_correction import apply_transform, estimate_motion\n",
    "from minian.preprocessing import denoise, remove_background\n",
    "from minian.utilities import (\n",
    "    TaskAnnotation,\n",
    "    get_optimal_chk,\n",
    "    load_videos,\n",
    "    open_minian,\n",
    "    save_minian,\n",
    ")\n",
    "from minian.visualization import (\n",
    "    CNMFViewer,\n",
    "    VArrayViewer,\n",
    "    generate_videos,\n",
    "    visualize_gmm_fit,\n",
    "    visualize_motion,\n",
    "    visualize_preprocess,\n",
    "    visualize_seeds,\n",
    "    visualize_spatial_update,\n",
    "    visualize_temporal_update,\n",
    "    write_video,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## module initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "dpath = os.path.abspath(dpath)\n",
    "hv.notebook_extension(\"bokeh\", width=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## start cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = LocalCluster(\n",
    "    n_workers=n_workers,\n",
    "    memory_limit=\"4GB\",\n",
    "    resources={\"MEM\": 1},\n",
    "    threads_per_worker=2,\n",
    "    dashboard_address=\":23456\",\n",
    ")\n",
    "annt_plugin = TaskAnnotation()\n",
    "cluster.scheduler.add_plugin(annt_plugin)\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loading videos and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "varr = load_videos(dpath, **param_load_videos)\n",
    "chk, _ = get_optimal_chk(varr, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "varr = save_minian(\n",
    "    varr.chunk({\"frame\": chk[\"frame\"], \"height\": -1, \"width\": -1}).rename(\"varr\"),\n",
    "    intpath,\n",
    "    overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualize raw data and optionally set roi for motion correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.output(size=output_size)\n",
    "if interactive:\n",
    "    vaviewer = VArrayViewer(varr, framerate=5, summary=[\"mean\", \"max\"])\n",
    "    display(vaviewer.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if interactive:\n",
    "    try:\n",
    "        subset_mc = list(vaviewer.mask.values())[0]\n",
    "    except IndexError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## subset part of video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varr_ref = varr.sel(subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## glow removal and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "varr_min = varr_ref.min(\"frame\").compute()\n",
    "varr_ref = varr_ref - varr_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.output(size=int(output_size * 0.7))\n",
    "if interactive:\n",
    "    vaviewer = VArrayViewer(\n",
    "        [varr.rename(\"original\"), varr_ref.rename(\"glow_removed\")],\n",
    "        framerate=5,\n",
    "        summary=None,\n",
    "        layout=True,\n",
    "    )\n",
    "    display(vaviewer.show())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## denoise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.output(size=int(output_size * 0.6))\n",
    "if interactive:\n",
    "    display(\n",
    "        visualize_preprocess(\n",
    "            varr_ref.isel(frame=0).compute(),\n",
    "            denoise,\n",
    "            method=[\"median\"],\n",
    "            ksize=[5, 7, 9],\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell would carry out denoise step.\n",
    "Be sure to [change the parameters](https://minian.readthedocs.io/page/start_guide/faq.html#i-don-t-know-python-can-i-still-use-the-pipeline) based on visualization results before running the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varr_ref = denoise(varr_ref, **param_denoise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## glow removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varr_ref = remove_background(varr_ref.astype(float), method='uniform', wnd=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## background removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.output(size=int(output_size * 0.6))\n",
    "if interactive:\n",
    "    display(\n",
    "        visualize_preprocess(\n",
    "            varr_ref.isel(frame=0).compute(),\n",
    "            remove_background,\n",
    "            method=[\"tophat\"],\n",
    "            wnd=[10, 15, 20],\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell would carry out background removal step.\n",
    "Be sure to [change the parameters](https://minian.readthedocs.io/page/start_guide/faq.html#i-don-t-know-python-can-i-still-use-the-pipeline) based on visualization results before running the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varr_ref = remove_background(varr_ref, **param_background_removal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "varr_ref = save_minian(varr_ref.rename(\"varr_ref\"), dpath=intpath, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motion Correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## estimate motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "motion = estimate_motion(varr_ref.sel(subset_mc), **param_estimate_motion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "motion = save_minian(\n",
    "    motion.rename(\"motion\").chunk({\"frame\": chk[\"frame\"]}), **param_save_minian\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualization of motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.output(size=output_size)\n",
    "visualize_motion(motion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## apply transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Y = apply_transform(varr_ref, motion, fill=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "Y_fm_chk = save_minian(Y.astype(float).rename(\"Y_fm_chk\"), intpath, overwrite=True)\n",
    "Y_hw_chk = save_minian(\n",
    "    Y_fm_chk.rename(\"Y_hw_chk\"),\n",
    "    intpath,\n",
    "    overwrite=True,\n",
    "    chunks={\"frame\": -1, \"height\": chk[\"height\"], \"width\": chk[\"width\"]},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualization of motion-correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_opts = dict(\n",
    "    frame_width=500,\n",
    "    aspect=varr_ref.sizes[\"width\"] / varr_ref.sizes[\"height\"],\n",
    "    cmap=\"Viridis\",\n",
    "    colorbar=True,\n",
    ")\n",
    "(\n",
    "    regrid(\n",
    "        hv.Image(\n",
    "            varr_ref.max(\"frame\").compute().astype(np.float32),\n",
    "            [\"width\", \"height\"],\n",
    "            label=\"before_mc\",\n",
    "        ).opts(**im_opts)\n",
    "    )\n",
    "    + regrid(\n",
    "        hv.Image(\n",
    "            Y_hw_chk.max(\"frame\").compute().astype(np.float32),\n",
    "            [\"width\", \"height\"],\n",
    "            label=\"after_mc\",\n",
    "        ).opts(**im_opts)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_ds = open_minian(intpath, return_dict=True)\n",
    "Y_fm_chk = temp_ds['Y_fm_chk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minian_ds = open_minian(param_save_minian['dpath'], return_dict=True)\n",
    "motion = minian_ds['motion']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compute max projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_proj = save_minian(\n",
    "    Y_fm_chk.max(\"frame\").rename(\"max_proj\"), **param_save_minian\n",
    ").compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generating over-complete set of seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from minian.initialization import local_max_roll\n",
    "\n",
    "def find_seed(\n",
    "    max_proj: xr.DataArray,\n",
    "    max_wnd=10,\n",
    "    diff_thres=2,\n",
    "):\n",
    "    loc_max = xr.apply_ufunc(\n",
    "        local_max_roll,\n",
    "        max_proj,\n",
    "        input_core_dims=[[\"height\", \"width\"]],\n",
    "        output_core_dims=[[\"height\", \"width\"]],\n",
    "        vectorize=True,\n",
    "        dask=\"parallelized\",\n",
    "        output_dtypes=[np.uint8],\n",
    "        kwargs=dict(k0=8, k1=max_wnd+1, diff=diff_thres),\n",
    "    )\n",
    "    seeds = (\n",
    "        loc_max.where(loc_max > 0).rename(\"seeds\").to_dataframe().dropna().reset_index()\n",
    "    )\n",
    "    return seeds[[\"height\", \"width\", \"seeds\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "seeds = find_seed(max_proj, max_wnd=15, diff_thres=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.output(size=output_size)\n",
    "visualize_seeds(max_proj, seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_size = 9 * 9 * np.pi\n",
    "img = cv2.cvtColor((norm(max_proj.values) * 255).astype(np.uint8), cv2.COLOR_GRAY2BGR)\n",
    "sd_idx = seeds.index + 2\n",
    "ws_dict = dict()\n",
    "ws_df = []\n",
    "for bg_thres in range(10):\n",
    "    marker = np.zeros_like(max_proj)\n",
    "    marker[max_proj.values <= bg_thres] = 1\n",
    "    marker[seeds['height'], seeds['width']] = sd_idx\n",
    "    marker = marker.astype(np.int32)\n",
    "    ws = cv2.watershed(img, marker.copy())\n",
    "    ws_dict[bg_thres] = ws\n",
    "    for isd in sd_idx:\n",
    "        \n",
    "ws = xr.DataArray(ws, dims=['height', 'width'], coords={'height': max_proj.coords['height'], 'width': max_proj.coords['width']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.morphology import disk\n",
    "exp_size = 8 * 8 * np.pi\n",
    "max_bg_thres = 10\n",
    "bg_erode = 5\n",
    "img = cv2.cvtColor((norm(max_proj.values) * 255).astype(np.uint8), cv2.COLOR_GRAY2BGR)\n",
    "erd_ele = disk(bg_erode)\n",
    "A_ls = []\n",
    "for isd, row in seeds.iterrows():\n",
    "    marker = np.zeros_like(max_proj, dtype=np.int32)\n",
    "    marker[int(row['height']), int(row['width'])] = 2\n",
    "    sizes = np.zeros(max_bg_thres)\n",
    "    wss = np.zeros((max_bg_thres, max_proj.shape[0], max_proj.shape[1]))\n",
    "    for ibg, bg_thres in enumerate(range(max_bg_thres)):\n",
    "        mk = marker.copy()\n",
    "        mk[cv2.erode((max_proj.values <= bg_thres).astype(np.uint8), erd_ele).astype(bool)] = 1\n",
    "        ws = cv2.watershed(img, mk.copy())\n",
    "        wss[ibg, :, :] = ws\n",
    "        sizes[ibg] = np.sum(ws == 2)\n",
    "    ws = wss[np.argmin(np.abs(sizes - exp_size)),:,:]\n",
    "    A = np.where(ws == 2, max_proj, np.nan)\n",
    "    A[np.isnan(A)] = np.nanmin(A)\n",
    "    A = norm(A)\n",
    "    A_ls.append(A)\n",
    "A = xr.DataArray(np.stack(A_ls, axis=0), dims=['unit_id', 'height', 'width'], coords={'unit_id': seeds.index, 'height': max_proj.coords['height'], 'width': max_proj.coords['width']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### intensity-based method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools as itt\n",
    "from skimage.measure import label as imlabel\n",
    "from skimage.morphology import disk\n",
    "exp_size = 6 * 6 * np.pi\n",
    "min_size = 6 * 6\n",
    "max_size = 15 * 15\n",
    "max_erode = 5\n",
    "dist_pow = 0.5\n",
    "dist = np.ones_like(max_proj, dtype=np.uint8)\n",
    "dist[seeds['height'], seeds['width']] = 0\n",
    "dist = cv2.distanceTransform(dist, cv2.DIST_L2, cv2.DIST_MASK_PRECISE)\n",
    "img = (norm(max_proj.values * ((dist + 1) ** -dist_pow)) * 255).astype(np.uint8)\n",
    "# img = (norm(max_proj.values) * 255).astype(np.uint8)\n",
    "# grd = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "# marker = np.zeros_like(max_proj, dtype=np.uint8)\n",
    "# marker[seeds['height'].values, seeds['width'].values] = seeds.index + 2\n",
    "# im_labs_erd = np.stack([imlabel(cv2.erode((img > thres).astype(np.uint8), disk(e))) for thres, e in itt.product(range(255), np.arange(max_erode))], axis=0)\n",
    "# im_labs_org = np.stack([imlabel(img > thres) for thres in range(255)], axis=0)\n",
    "# im_labs = np.concatenate([im_labs_org, im_labs_erd], axis=0)\n",
    "im_labs = np.stack([imlabel(img > thres) for thres in range(255)], axis=0)\n",
    "# im_ws = np.stack([cv2.watershed(grd, np.where(img > thres, marker, 1).astype(np.int32)) for thres in range(255)], axis=0)\n",
    "# im_labs = np.concatenate([im_labs, im_ws], axis=0)\n",
    "A_ls = []\n",
    "idx_ls = []\n",
    "for isd, row in seeds.iterrows():\n",
    "    h, w = int(row['height']), int(row['width'])\n",
    "    labs = im_labs[:, h, w]\n",
    "    im_sd = im_labs == labs[:, np.newaxis, np.newaxis]\n",
    "    im_sd = im_sd[labs > 0, :, :]\n",
    "    sizes = im_sd.sum(axis=(1, 2))\n",
    "    im_sd = im_sd[np.logical_and(sizes > min_size, sizes < max_size), :, :]\n",
    "    if len(im_sd)>0:\n",
    "        cvx = np.array([convexity_score(im) for im in im_sd])\n",
    "        # size_diff = np.abs(sizes - exp_size) / exp_size\n",
    "        # sidx = np.argmin(np.abs(sizes - exp_size))\n",
    "        sidx = np.argmax(cvx)\n",
    "        mask = im_sd[sidx, :, :]\n",
    "        curA = np.where(mask, max_proj, np.nan)\n",
    "        curA[np.isnan(curA)] = np.nanmin(curA)\n",
    "        A_ls.append(norm(curA))\n",
    "        idx_ls.append(isd)\n",
    "A = xr.DataArray(np.stack(A_ls, axis=0), dims=['unit_id', 'height', 'width'], coords={'unit_id': idx_ls, 'height': max_proj.coords['height'], 'width': max_proj.coords['width']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_ls = []\n",
    "for isd, row in seeds.iterrows():\n",
    "    marker = np.zeros_like(max_proj, dtype=np.int32)\n",
    "    marker[int(row['height']), int(row['width'])] = 2\n",
    "    sizes = np.zeros(max_bg_thres)\n",
    "    wss = np.zeros((max_bg_thres, max_proj.shape[0], max_proj.shape[1]))\n",
    "    for ibg, bg_thres in enumerate(range(max_bg_thres)):\n",
    "        mk = marker.copy()\n",
    "        mk[cv2.erode((max_proj.values <= bg_thres).astype(np.uint8), erd_ele).astype(bool)] = 1\n",
    "        ws = cv2.watershed(img, mk.copy())\n",
    "        wss[ibg, :, :] = ws\n",
    "        sizes[ibg] = np.sum(ws == 2)\n",
    "    ws = wss[np.argmin(np.abs(sizes - exp_size)),:,:]\n",
    "    A = np.where(ws == 2, max_proj, np.nan)\n",
    "    A[np.isnan(A)] = np.nanmin(A)\n",
    "    A = norm(A)\n",
    "    A_ls.append(A)\n",
    "A = xr.DataArray(np.stack(A_ls, axis=0), dims=['unit_id', 'height', 'width'], coords={'unit_id': seeds.index, 'height': max_proj.coords['height'], 'width': max_proj.coords['width']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gradient-based method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from skimage.measure import label as imlabel\n",
    "from skimage.morphology import disk\n",
    "\n",
    "def im_floodfill(im):\n",
    "    im_floodfill = im.astype(np.uint8)\n",
    "    h, w = im.shape\n",
    "    mask = np.zeros((h+2, w+2), np.uint8)\n",
    "    cv2.floodFill(im_floodfill, mask, (0,0), 255);\n",
    "    return im_floodfill != 255\n",
    "\n",
    "\n",
    "min_size = 8 * 8\n",
    "max_size = 25 * 25\n",
    "grd_thres = np.arange(-150, 1, 1)\n",
    "# pad = int(np.sqrt(min_size) / 2 - 1)\n",
    "pad = 2\n",
    "\n",
    "img = np.array(max_proj)\n",
    "# dx = cv2.Scharr(img, ddepth=-1, dx=1, dy=0)\n",
    "# dy = cv2.Scharr(img, ddepth=-1, dx=0, dy=1)\n",
    "dx = cv2.Sobel(img, ddepth=-1, dx=1, dy=0)\n",
    "dy = cv2.Sobel(img, ddepth=-1, dx=0, dy=1)\n",
    "mag = np.sqrt(dx**2 + dy**2)\n",
    "ang = np.arctan2(dy, dx)\n",
    "# mag = cv2.medianBlur(mag.astype(np.float32), 5)\n",
    "# ang = cv2.medianBlur(ang.astype(np.float32), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_ls = []\n",
    "idx_ls = []\n",
    "for isd, row in seeds.iterrows():\n",
    "    sd_h, sd_w = int(row['height']), int(row['width'])\n",
    "    gy = np.tile(np.arange(img.shape[0])[:, np.newaxis], (1, img.shape[1])) - sd_h\n",
    "    gx = np.tile(np.arange(img.shape[1])[np.newaxis, :], (img.shape[0], 1)) - sd_w\n",
    "    gang = np.arctan2(gy, gx)\n",
    "    proj = (mag * np.cos(gang - ang))\n",
    "    im_labs = np.stack([proj < thres for thres in grd_thres], axis=0)\n",
    "    im_labs[:, max(sd_h - pad, 0):sd_h+pad, max(sd_w-pad, 0):sd_w+pad] = True\n",
    "    im_labs = np.stack([imlabel(im) for im in im_labs], axis=0)\n",
    "    labs = im_labs[:, sd_h, sd_w]\n",
    "    im_sd = im_labs == labs[:, np.newaxis, np.newaxis]\n",
    "    sizes = im_sd.sum(axis=(1, 2))\n",
    "    im_sd = im_sd[np.logical_and(sizes > min_size, sizes < max_size), :, :]\n",
    "    if len(im_sd)>0:\n",
    "        cvx = np.array([convexity_score(im) for im in im_sd])\n",
    "        sidx = np.argmax(cvx)\n",
    "        mask = im_floodfill(im_sd[sidx, :, :])\n",
    "        curA = np.where(mask, max_proj, np.nan)\n",
    "        curA[np.isnan(curA)] = np.nanmin(curA)\n",
    "        A_ls.append(norm(curA))\n",
    "        idx_ls.append(isd)\n",
    "A = xr.DataArray(np.stack(A_ls, axis=0), dims=['unit_id', 'height', 'width'], coords={'unit_id': idx_ls, 'height': max_proj.coords['height'], 'width': max_proj.coords['width']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(a):\n",
    "    amin, amax = a.min(), a.max()\n",
    "    return (a - amin) / (amax - amin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convexity_score(im):\n",
    "    cnt = cv2.findContours(im.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)[0][0]\n",
    "    peri = cv2.arcLength(cnt, True)\n",
    "    hull = cv2.convexHull(cnt)\n",
    "    peri_hull = cv2.arcLength(hull, True)\n",
    "    if peri > 0:\n",
    "        return peri_hull / peri\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize_scalar\n",
    "\n",
    "A_ls = []\n",
    "idx_ls = []\n",
    "def cvx_opt_cb(thres, proj, min_size, pad, sd_h, sd_w):\n",
    "    im_labs = proj < thres\n",
    "    im_labs[max(sd_h - pad, 0):sd_h+pad, max(sd_w-pad, 0):sd_w+pad] = True\n",
    "    im_labs = imlabel(im_labs)\n",
    "    labs = im_labs[sd_h, sd_w]\n",
    "    im_sd = im_labs == labs\n",
    "    size = im_sd.sum()\n",
    "    if size > min_size:\n",
    "        return -convexity_score(im_sd)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "for isd, row in seeds.iterrows():\n",
    "    sd_h, sd_w = int(row['height']), int(row['width'])\n",
    "    gy = np.tile(np.arange(img.shape[0])[:, np.newaxis], (1, img.shape[1])) - sd_h\n",
    "    gx = np.tile(np.arange(img.shape[1])[np.newaxis, :], (img.shape[0], 1)) - sd_w\n",
    "    gang = np.arctan2(gy, gx)\n",
    "    proj = (mag * np.cos(gang - ang))\n",
    "    res = minimize_scalar(cvx_opt_cb, bounds=(-200, 5), args=(proj, min_size, pad, sd_h, sd_w), method='Bounded')\n",
    "    if res.success:\n",
    "        im_labs = proj < res.x\n",
    "        im_labs[max(sd_h - pad, 0):sd_h+pad, max(sd_w-pad, 0):sd_w+pad] = True\n",
    "        im_labs = imlabel(im_labs)\n",
    "        labs = im_labs[sd_h, sd_w]\n",
    "        mask = im_floodfill(im_labs == labs)\n",
    "        curA = np.where(mask, max_proj, np.nan)\n",
    "        curA[np.isnan(curA)] = np.nanmin(curA)\n",
    "        A_ls.append(norm(curA))\n",
    "        idx_ls.append(isd)\n",
    "A = xr.DataArray(np.stack(A_ls, axis=0), dims=['unit_id', 'height', 'width'], coords={'unit_id': idx_ls, 'height': max_proj.coords['height'], 'width': max_proj.coords['width']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis = xr.DataArray(proj.clip(-100, 100), dims=['height', 'width'], coords={'height': max_proj.coords['height'], 'width': max_proj.coords['width']})\n",
    "visualize_seeds(max_proj, seeds) + hv.Image(vis, ['width', 'height']).opts(cmap='RdBu', frame_width=608, frame_height=608, symmetric=True, colorbar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jac_thres = 1\n",
    "A_bl = np.array((A > 0).astype(float))\n",
    "A_inter = np.tensordot(A_bl, np.moveaxis(A_bl, 0, -1))\n",
    "A_sum = np.tile(A_bl.sum(axis=(1, 2)), (A_bl.shape[0], 1))\n",
    "A_sum = A_sum + A_sum.T\n",
    "jac = A_inter / (A_sum - A_inter)\n",
    "np.fill_diagonal(jac, 0)\n",
    "lab = label_connected(jac >= jac_thres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise_distances\n",
    "from minian.cnmf import label_connected\n",
    "cos_thres = 0.5\n",
    "cos = 1 - pairwise_distances(np.array(A).reshape((A.shape[0], -1)), metric='cosine', n_jobs=-1)\n",
    "np.fill_diagonal(cos, 0)\n",
    "lab = label_connected(cos >= cos_thres)\n",
    "A_merged = (\n",
    "        A.assign_coords(unit_labels=(\"unit_id\", lab))\n",
    "        .groupby(\"unit_labels\")\n",
    "        .mean(\"unit_id\")\n",
    "        .rename(unit_labels=\"unit_id\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u, c = np.unique(lab, return_counts=True)\n",
    "dup = u[c > 1]\n",
    "duplicated = np.isin(lab, dup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    visualize_seeds(max_proj, seeds)\n",
    "    + hv.Image(A.max('unit_id'), ['width', 'height']).opts(cmap='viridis', frame_width=608, frame_height=608)\n",
    "    + hv.Image(A.sel(unit_id=duplicated).max('unit_id'), ['width', 'height']).opts(cmap='viridis', frame_width=608, frame_height=608)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = hv.Image(max_proj, ['width', 'height']).opts(cmap='viridis', frame_width=608, frame_height=608)\n",
    "for uid in A_merged.coords['unit_id'].values:\n",
    "    curA = (np.array(A_merged.sel(unit_id=uid)) > 0).astype(np.uint8)\n",
    "    cnt = cv2.findContours(curA, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)[0][0].squeeze()\n",
    "    if cnt.ndim > 1:\n",
    "        im = im * hv.Path(cnt.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.output(size=80)\n",
    "visualize_seeds(max_proj, seeds) + im + hv.Image(A_merged.max('unit_id'), ['width', 'height']).opts(cmap='viridis', frame_width=608, frame_height=608)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_ds = xr.merge([motion, max_proj, A_merged.rename('A')])\n",
    "out_path = \"../intermediate/processed/red/\"\n",
    "os.makedirs(out_path, exist_ok=True)\n",
    "out_ds.to_netcdf(os.path.join(out_path, \"m15-rec1.nc\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "2s_validation-minian",
   "language": "python",
   "name": "2s_validation-minian"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "name": "pipeline.ipynb",
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": true,
  "vscode": {
   "interpreter": {
    "hash": "02fb8f0d17ed08cd17073dfc238056079f9da35e3c53ceb57bad40262caa5acb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
